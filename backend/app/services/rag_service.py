# backend/app/services/rag_service.py
import os
import asyncio
from typing import AsyncGenerator
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# í´ë˜ìŠ¤ ì´ˆê¸°í™” ì‹œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class RAGService:
    def __init__(self, db_path="my_faiss_index"): 
        if "OPENAI_API_KEY" not in os.environ:
            print("âš ï¸ [ê²½ê³ ] OPENAI_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸš€ RAG Serviceë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤... (DB ê²½ë¡œ: {db_path})")
        try:
            # 1. ëª¨ë¸ ì„¤ì • (Fact Checkë¥¼ ìœ„í•´ temperature=0)
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
            embeddings = OpenAIEmbeddings()
            
            # 2. ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ
            if not os.path.exists(db_path):
                # ê²½ë¡œê°€ í‹€ë ¸ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ìƒìœ„ í´ë”ë„ í•œë²ˆ ì²´í¬
                alt_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "my_faiss_index")
                if os.path.exists(alt_path):
                    db_path = alt_path
                else:
                    raise FileNotFoundError(f"ë²¡í„° DB í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}")

            vector_store = FAISS.load_local(
                folder_path=db_path, 
                embeddings=embeddings, 
                allow_dangerous_deserialization=True
            )
            retriever = vector_store.as_retriever(search_kwargs={"k": 3})

            # 3. â­ï¸ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ (ê°€ë…ì„± + íŒ©íŠ¸ì²´í¬ ê°•í™”)
            prompt_template = """
            ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ê¼¼ê¼¼í•œ 'ì¬í™œìš© ë¶„ë¦¬ë°°ì¶œ ë„ìš°ë¯¸'ì…ë‹ˆë‹¤.
            ì•„ë˜ [ì œê³µëœ ì •ë³´(Context)]ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [ì§ˆë¬¸(Question)]ì— ë‹µë³€í•˜ì„¸ìš”.

            [ì§€ì¹¨]
            1. **ì—„ê²©í•œ ì‚¬ì‹¤ ê¸°ë°˜**: [ì œê³µëœ ì •ë³´]ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ "ì£„ì†¡í•˜ì§€ë§Œ ì œê³µëœ ìë£Œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ë‚˜ì™€ìˆì§€ ì•Šì•„ìš”."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.
            2. **ì¹œì ˆí•œ í†¤**: ë‹µë³€ì€ ì¡´ëŒ“ë§ë¡œ, ë¶€ë“œëŸ½ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
            3. **ê°€ë…ì„±**: 
               - ë‹µë³€ì´ ê¸¸ì–´ì§€ë©´ ì¤„ë°”ê¿ˆì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”.
               - í•µì‹¬ ë‚´ìš©ì€ **êµµê²Œ** í‘œì‹œí•˜ì„¸ìš”.
               - ë²ˆí˜¸ ë§¤ê¸°ê¸°(1., 2.)ë‚˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(-)ë¥¼ ì‚¬ìš©í•´ ì •ë¦¬í•˜ì„¸ìš”.
               - ì ì ˆí•œ ê³³ì— ì´ëª¨ì§€(ğŸŒ±, â™»ï¸, ğŸ—‘ï¸ ë“±)ë¥¼ ì‚¬ìš©í•´ ë‹µë³€ì„ ìƒë™ê° ìˆê²Œ ë§Œë“œì„¸ìš”.

            [ì œê³µëœ ì •ë³´(Context)]
            {context}

            [ì§ˆë¬¸(Question)]
            {question}

            [ë‹µë³€]
            """
            
            PROMPT = PromptTemplate(
                template=prompt_template, input_variables=["context", "question"]
            )

            # 4. ì²´ì¸ ìƒì„±
            self.chain = (
                {"context": retriever, "question": RunnablePassthrough()}
                | PROMPT
                | llm
                | StrOutputParser()
            )
            print("  > âœ… RAG ì²´ì¸ ìƒì„± ì™„ë£Œ.")
            
        except Exception as e:
            print(f"âŒ [ì¹˜ëª…ì  ì˜¤ë¥˜] RAG ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.chain = None

    # ---------------------------------------------------------
    # ê³µí†µ ì§ˆë¬¸ ìƒì„± ë¡œì§ (ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë¶„ë¦¬)
    # ---------------------------------------------------------
    def _create_final_question(self, user_input: str, image_class: str) -> str:
        if image_class and user_input:
             return f"ì‚¬ì§„ì—ì„œ ê°ì§€ëœ ë¬¼ì²´ëŠ” '{image_class}'ì…ë‹ˆë‹¤. ì´ ë¬¼ì²´ì™€ ê´€ë ¨í•˜ì—¬ ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤: '{user_input}'. ì´ ë¬¼ì²´ì˜ ì˜¬ë°”ë¥¸ ë¶„ë¦¬ë°°ì¶œ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        elif user_input:
            return user_input
        elif image_class:
            return f"ì‚¬ì§„ì—ì„œ '{image_class}'(ì´)ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ê²ƒì˜ ì˜¬ë°”ë¥¸ ë¶„ë¦¬ë°°ì¶œ ë°©ë²•ì„ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”."
        return ""

    # ---------------------------------------------------------
    # 1. ì¼ë°˜ ì‘ë‹µ (ë™ê¸° ë°©ì‹ - YOLO API ë“±ì—ì„œ ì‚¬ìš©)
    # ---------------------------------------------------------
    def get_response(self, user_input: str, image_class: str) -> str:
        if not self.chain:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. RAG ì„œë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        final_question = self._create_final_question(user_input, image_class)
        if not final_question:
            return "ì§ˆë¬¸í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

        try:
            return self.chain.invoke(final_question)
        except Exception as e:
            print(f"RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    # ---------------------------------------------------------
    # 2. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ë¹„ë™ê¸° ë°©ì‹ - ì±„íŒ… APIì—ì„œ ì‚¬ìš©)
    # ---------------------------------------------------------
    async def stream_response(self, user_input: str, image_class: str) -> AsyncGenerator[str, None]:
        if not self.chain:
            yield "ì£„ì†¡í•©ë‹ˆë‹¤. RAG ì„œë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            return

        final_question = self._create_final_question(user_input, image_class)
        if not final_question:
            yield "ì§ˆë¬¸í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
            return

        try:
            # LangChainì˜ astreamì„ ì‚¬ìš©í•˜ì—¬ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            async for chunk in self.chain.astream(final_question):
                yield chunk 
                await asyncio.sleep(0.01) # ë„ˆë¬´ ë¹ ë¥¸ ì „ì†¡ ë°©ì§€
        except Exception as e:
            print(f"RAG ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}")
            yield f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"